{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----IMPORT LIBRAIRIES----\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "import pvlib\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import Model_func as mf\n",
    "import boto3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5648ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---VARIABLES----\n",
    "weather_data_path = 'https://renergies99-bucket.s3.eu-west-3.amazonaws.com/public/openweathermap/merge_openweathermap_cleaned.csv'\n",
    "solar_data_path = 'https://renergies99-bucket.s3.eu-west-3.amazonaws.com/public/solar/raw_solar_data.csv'\n",
    "landsat_data_path = 'https://renergies99-bucket.s3.eu-west-3.amazonaws.com/public/LandSat/result_EarthExplorer_region_ARA.csv'\n",
    "\n",
    "prod_data_path = 'https://renergies99-bucket.s3.eu-west-3.amazonaws.com/public/prod/eCO2mix_RTE_Auvergne-Rhone-Alpes_cleaned.csv'\n",
    "target = 'tch_solaire_(%)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- PREPARATION ----\n",
    "collected_weather_data = mf.data_collection_weather(weather_data_path) # collect data and format columns per city\n",
    "collected_solar_data = mf.data_coll_solar(solar_data_path)\n",
    "collected_landsat_data = mf.data_coll_landsat(landsat_data_path)\n",
    "landsat_data = collected_landsat_data.copy()\n",
    "\n",
    "weather_solar = mf.merge_weather_solar_data(collected_weather_data, collected_solar_data)\n",
    "\n",
    "#creer un df landsat réduit avec 1 donnée/jour\n",
    "columns_to_keep = landsat_data.select_dtypes(exclude=[\"object\"]).columns\n",
    "limited_landsat_data = landsat_data[columns_to_keep].groupby('Time').mean().reset_index()\n",
    " \n",
    "merged_data = mf.merge_weather_solar_landsat_data(collected_weather_data, collected_solar_data, limited_landsat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data_copy = pd.read_csv('../../../Mes_fichiers_vrac/merged_data_copy.csv')\n",
    "# merged_data_copy['Time'] = pd.to_datetime(merged_data_copy['Time'])\n",
    "\n",
    "# merged_data = merged_data_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938196bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---data_split : add target and train_test_split\n",
    "prod_data = mf.data_collection_prod(prod_data_path)\n",
    "targeted_data = mf.add_target(merged_data, prod_data, target_columns_to_use=['Time', target])\n",
    "\n",
    "#---columns selection\n",
    "col_solar = ['Ap', '10cm', 'K index Planetary']\n",
    "col_weather = ['temp', 'feels_like' 'pressure', 'humidity', 'dew_point',\n",
    "                'clouds', 'wind_speed', 'wind_deg']\n",
    "features = col_weather + col_solar + ['Moulins_day_length']\n",
    "\n",
    "selected_weather_columns = [col for col in targeted_data.columns if col.endswith(tuple(col_weather))]\n",
    "selected_columns = selected_weather_columns + col_solar + ['Moulins_day_length']\n",
    "\n",
    "y = targeted_data[target].to_numpy()\n",
    "X = targeted_data[selected_columns]\n",
    "\n",
    "#--- gestion de NaN\n",
    "X = X.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---MLFlow params\n",
    "os.environ[\"APP_URI\"] = \"https://renergies99-mlflow.hf.space/\"\n",
    "EXPERIMENT_NAME = \"all_columns_models\"\n",
    "\n",
    "mlflow.set_tracking_uri(os.environ[\"APP_URI\"])\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "mlflow.sklearn.autolog()  # enables automatic logging for scikit-learn\n",
    "\n",
    "#---Preprocess\n",
    "result_preprocess = mf.preprocessing_and_pipeline(X)\n",
    "pipeline = result_preprocess[\"pipeline\"]\n",
    "preprocessor = result_preprocess[\"preprocessor\"]\n",
    "\n",
    "run_description = (\n",
    "    f\"Features used: {features}\\nTarget: {target}\\n\"\n",
    "    f\"Estimator: {pipeline.named_steps['estimator']}\"\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=24)\n",
    "input_example = x_train.iloc[:3]\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment.experiment_id, description=run_description):\n",
    "    # Fit the pipeline (preprocessing + model)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "\n",
    "    # signature\n",
    "    signature = infer_signature(x_test, pipeline.predict(x_test))\n",
    "\n",
    "    # predictions\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "\n",
    "    #Artifact for features_names\n",
    "    #mf.custom_get_feature_names(result_preprocess, artifact_name=\"features.json\")\n",
    " \n",
    "    #artifact for confidence interval\n",
    "    error = mf.error_stat(x_test, y_test, pipeline)\n",
    "    error.to_json(\"error.json\")\n",
    "    mlflow.log_artifact(\"error.json\")\n",
    "    \n",
    "    # metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    n = len(y_test)\n",
    "    p = X.shape[1]\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "    \n",
    "    # logging metrics\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"MSE\", mse)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"R2\", r2)\n",
    "    mlflow.log_metric(\"Adjusted_R2\", adj_r2)\n",
    " \n",
    "    # Log the full pipeline as a model\n",
    "    mlflow.sklearn.log_model(pipeline, signature=signature, input_example=input_example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50aca3",
   "metadata": {},
   "source": [
    "# Results exploration\n",
    "Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bad6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = pipeline.named_steps['preprocessor']\n",
    "\n",
    "feature_names = []\n",
    "\n",
    "for name, transformer, cols in preprocessor.transformers:\n",
    "    if name == 'num':\n",
    "        feature_names.extend(cols)  # StandardScaler ne change pas le nombre de colonnes\n",
    "    elif name == 'obj':\n",
    "        feature_names.extend(cols)  # passthrough garde les colonnes telles quelles\n",
    "\n",
    "# Récupérer les coefficients du modèle\n",
    "coefs = pipeline.named_steps['estimator'].coef_\n",
    "\n",
    "print(len(feature_names), len(coefs))\n",
    "\n",
    "# Tracer les coefs (triés en valuer absolue)\n",
    "df_coef = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefs\n",
    "})\n",
    "df_coef = df_coef.sort_values(by='coefficient', key=abs)\n",
    "\n",
    "px.bar(df_coef, x='coefficient', y='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b933c6d",
   "metadata": {},
   "source": [
    "Erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347824cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des prédictions et des résidus\n",
    "y_pred = pipeline.predict(x_test)\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Création de la figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Ajout des résidus\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_pred,\n",
    "    y=residuals,\n",
    "    mode='markers',\n",
    "    name='Résidus',\n",
    "    marker=dict(color='blue', size=8)\n",
    "))\n",
    "\n",
    "# Ligne horizontale y=0\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[min(y_pred), max(y_pred)],\n",
    "    y=[0, 0],\n",
    "    mode='lines',\n",
    "    line=dict(color='red', dash='dash'),\n",
    "    name='Zéro'\n",
    "))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title=\"Residual Plot\",\n",
    "    xaxis_title=\"Predictions\",\n",
    "    yaxis_title=\"Residuals\",\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5cc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du DataFrame pour Plotly Express\n",
    "df_plot = pd.DataFrame({\n",
    "    'y_test': y_test,\n",
    "    'y_pred': y_pred\n",
    "})\n",
    "\n",
    "# Scatter plot\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x='y_test',\n",
    "    y='y_pred',\n",
    "    labels={'y_test': 'Valeurs réelles tch', 'y_pred': 'Prédictions'},\n",
    "    title='Prédictions vs Valeurs réelles'\n",
    ")\n",
    "\n",
    "# Ajouter une ligne y=x pour visualiser l’idéal\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=df_plot['y_test'].min(),\n",
    "    y0=df_plot['y_test'].min(),\n",
    "    x1=df_plot['y_test'].max(),\n",
    "    y1=df_plot['y_test'].max(),\n",
    "    line=dict(color='red', dash='dash')\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c115772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Finalproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
